{
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ogfiUz69LuSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install earthengine-api\n",
        "\n",
        "import os\n",
        "import ee\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "# Config\n",
        "PROJECT_ID = \"asean-envoirmental-project\"\n",
        "OUT_CSV    = \"thailand_rice_env_s1_s2_full.csv\"\n",
        "\n",
        "STRATIFY_BY_LABEL = False\n",
        "POINTS_PER_CLASS_PER_REGION = 10\n",
        "NUM_POINTS_PER_REGION       = 200\n",
        "\n",
        "SUPERVISED_RICE_ASSET_ID = \"projects/asean-envoirmental-project/assets/MSEAsia2019\"\n",
        "LABEL_YEAR = 2019\n",
        "\n",
        "S2_COLLECTION = \"COPERNICUS/S2_SR_HARMONIZED\"\n",
        "\n",
        "# Earth Engine init\n",
        "os.environ[\"EARTHENGINE_PROJECT\"] = PROJECT_ID\n",
        "try:\n",
        "    ee.Initialize(project=PROJECT_ID)\n",
        "except Exception:\n",
        "    ee.Authenticate(auth_mode=\"notebook\")\n",
        "    ee.Initialize(project=PROJECT_ID)\n",
        "\n",
        "print(\"EE project:\", PROJECT_ID)\n",
        "\n",
        "# Study area\n",
        "thailand = ee.FeatureCollection(\"FAO/GAUL/2015/level0\").filter(\n",
        "    ee.Filter.eq(\"ADM0_NAME\", \"Thailand\")\n",
        ")\n",
        "\n",
        "regions = {\n",
        "    \"Central\":   {\"lat\": 14.5, \"lon\": 100.5, \"radius\": 50000},\n",
        "    \"Northeast\": {\"lat\": 16.5, \"lon\": 103.0, \"radius\": 50000},\n",
        "    \"North\":     {\"lat\": 18.5, \"lon\":  99.0, \"radius\": 50000},\n",
        "    \"South\":     {\"lat\":  8.0, \"lon\":  99.5, \"radius\": 50000},\n",
        "}\n",
        "\n",
        "def region_geom(region_info):\n",
        "    center = ee.Geometry.Point([region_info[\"lon\"], region_info[\"lat\"]])\n",
        "    return center.buffer(region_info[\"radius\"])\n",
        "\n",
        "# Labels from 2019 MSEAsia supervised rice mask\n",
        "def load_supervised_rice_image():\n",
        "    print(\"\\nLoading supervised rice (MSE Asia 2019)…\")\n",
        "    raw = ee.Image(SUPERVISED_RICE_ASSET_ID).select(\"b1\").clip(thailand.geometry())\n",
        "    rice_bin = raw.eq(255).rename(\"rice\")\n",
        "    kernel = ee.Kernel.square(60, \"meters\", True)\n",
        "    rice_mode = rice_bin.reduceNeighborhood(ee.Reducer.mode(), kernel).rename(\"rice\")\n",
        "    print(\"OK: binary rice (0/1), 20 m grid\")\n",
        "    return rice_mode\n",
        "\n",
        "RICE_IMG = load_supervised_rice_image()\n",
        "\n",
        "# ENV predictors\n",
        "def get_evi_metrics(point, year):\n",
        "    try:\n",
        "        col = (\n",
        "            ee.ImageCollection(\"MODIS/061/MOD13Q1\")\n",
        "            .filterDate(f\"{year}-05-01\", f\"{year}-11-30\")\n",
        "            .select(\"EVI\")\n",
        "        )\n",
        "        if col.size().getInfo() == 0:\n",
        "            return None, None, None\n",
        "\n",
        "        def scale_and_mask(img):\n",
        "            scaled = img.multiply(0.0001)\n",
        "            return scaled.updateMask(\n",
        "                scaled.gte(-0.2).And(scaled.lte(1.0))\n",
        "            ).copyProperties(img, img.propertyNames())\n",
        "\n",
        "        col_scaled = col.map(scale_and_mask)\n",
        "        combo = col_scaled.mean().addBands(\n",
        "            [col_scaled.max(), col_scaled.min()]\n",
        "        ).rename([\"mean_evi\", \"max_evi\", \"min_evi\"])\n",
        "        geom = point.geometry().buffer(500)\n",
        "\n",
        "        stats = combo.reduceRegion(\n",
        "            reducer=ee.Reducer.mean(),\n",
        "            geometry=geom,\n",
        "            scale=250,\n",
        "            maxPixels=1e9,\n",
        "            bestEffort=True,\n",
        "            tileScale=4,\n",
        "        )\n",
        "\n",
        "        mean_val = stats.get(\"mean_evi\")\n",
        "        max_val  = stats.get(\"max_evi\")\n",
        "        min_val  = stats.get(\"min_evi\")\n",
        "        if mean_val is None:\n",
        "            return None, None, None\n",
        "\n",
        "        mean_evi_val = float(ee.Number(mean_val).getInfo())\n",
        "        max_evi_val  = float(ee.Number(max_val).getInfo()) if max_val else None\n",
        "        min_evi_val  = float(ee.Number(min_val).getInfo()) if min_val else None\n",
        "        amp = (\n",
        "            max_evi_val - min_evi_val\n",
        "            if (max_evi_val is not None and min_evi_val is not None)\n",
        "            else None\n",
        "        )\n",
        "        return mean_evi_val, max_evi_val, amp\n",
        "    except Exception:\n",
        "        return None, None, None\n",
        "\n",
        "def get_lst_metrics(point, year):\n",
        "    try:\n",
        "        col = (\n",
        "            ee.ImageCollection(\"MODIS/061/MOD11A2\")\n",
        "            .filterDate(f\"{year}-05-01\", f\"{year}-11-30\")\n",
        "            .select(\"LST_Day_1km\")\n",
        "        )\n",
        "        if col.size().getInfo() == 0:\n",
        "            return None, None\n",
        "\n",
        "        def scale_and_mask(img):\n",
        "            kelvin  = img.multiply(0.02)\n",
        "            masked  = kelvin.updateMask(kelvin.gte(200).And(kelvin.lte(400)))\n",
        "            celsius = masked.subtract(273.15)\n",
        "            return celsius.copyProperties(img, img.propertyNames())\n",
        "\n",
        "        col_c = col.map(scale_and_mask)\n",
        "        combo = col_c.mean().addBands(col_c.max()).rename([\"mean_temp\", \"max_temp\"])\n",
        "        geom = point.geometry().buffer(1000)\n",
        "\n",
        "        stats = combo.reduceRegion(\n",
        "            reducer=ee.Reducer.mean(),\n",
        "            geometry=geom,\n",
        "            scale=1000,\n",
        "            maxPixels=1e9,\n",
        "            bestEffort=True,\n",
        "            tileScale=4,\n",
        "        )\n",
        "\n",
        "        mean_val = stats.get(\"mean_temp\")\n",
        "        max_val  = stats.get(\"max_temp\")\n",
        "        if mean_val is None:\n",
        "            return None, None\n",
        "\n",
        "        return float(ee.Number(mean_val).getInfo()), (\n",
        "            float(ee.Number(max_val).getInfo()) if max_val else None\n",
        "        )\n",
        "    except Exception:\n",
        "        return None, None\n",
        "\n",
        "def get_precipitation_metrics(point, year):\n",
        "    try:\n",
        "        chirps = (\n",
        "            ee.ImageCollection(\"UCSB-CHG/CHIRPS/DAILY\")\n",
        "            .filterDate(f\"{year}-01-01\", f\"{year}-12-31\")\n",
        "            .select(\"precipitation\")\n",
        "        )\n",
        "        if chirps.size().getInfo() == 0:\n",
        "            return None, None, None\n",
        "\n",
        "        annual_total = chirps.sum()\n",
        "        gs_total     = chirps.filter(\n",
        "            ee.Filter.calendarRange(5, 11, \"month\")\n",
        "        ).sum()\n",
        "        peak_total   = chirps.filter(\n",
        "            ee.Filter.calendarRange(7, 9, \"month\")\n",
        "        ).sum()\n",
        "        combo = annual_total.addBands(\n",
        "            [gs_total, peak_total]\n",
        "        ).rename([\"annual\", \"gs\", \"peak\"])\n",
        "        geom = point.geometry().buffer(5000)\n",
        "\n",
        "        stats = combo.reduceRegion(\n",
        "            reducer=ee.Reducer.mean(),\n",
        "            geometry=geom,\n",
        "            scale=5000,\n",
        "            maxPixels=1e9,\n",
        "            bestEffort=True,\n",
        "            tileScale=4,\n",
        "        )\n",
        "\n",
        "        a = stats.get(\"annual\")\n",
        "        g = stats.get(\"gs\")\n",
        "        p = stats.get(\"peak\")\n",
        "        if a is None:\n",
        "            return None, None, None\n",
        "\n",
        "        return float(ee.Number(a).getInfo()), (\n",
        "            float(ee.Number(g).getInfo()) if g else None\n",
        "        ), (\n",
        "            float(ee.Number(p).getInfo()) if p else None\n",
        "        )\n",
        "    except Exception:\n",
        "        return None, None, None\n",
        "\n",
        "def get_precipitation_metrics_era5(point, year):\n",
        "    try:\n",
        "        era5 = (\n",
        "            ee.ImageCollection(\"ECMWF/ERA5/DAILY\")\n",
        "            .filterDate(f\"{year}-01-01\", f\"{year}-12-31\")\n",
        "            .select(\"total_precipitation\")\n",
        "        )\n",
        "        if era5.size().getInfo() == 0:\n",
        "            return None, None, None\n",
        "\n",
        "        era5_mm = era5.map(\n",
        "            lambda img: img.multiply(1000).copyProperties(\n",
        "                img, img.propertyNames()\n",
        "            )\n",
        "        )\n",
        "        annual_total = era5_mm.sum()\n",
        "        gs_total     = era5_mm.filter(\n",
        "            ee.Filter.calendarRange(5, 11, \"month\")\n",
        "        ).sum()\n",
        "        peak_total   = era5_mm.filter(\n",
        "            ee.Filter.calendarRange(7, 9, \"month\")\n",
        "        ).sum()\n",
        "        combo = annual_total.addBands(\n",
        "            [gs_total, peak_total]\n",
        "        ).rename([\"annual\", \"gs\", \"peak\"])\n",
        "        geom = point.geometry().buffer(27000)\n",
        "\n",
        "        stats = combo.reduceRegion(\n",
        "            reducer=ee.Reducer.mean(),\n",
        "            geometry=geom,\n",
        "            scale=27830,\n",
        "            maxPixels=1e9,\n",
        "            bestEffort=True,\n",
        "            tileScale=4,\n",
        "        )\n",
        "\n",
        "        a = stats.get(\"annual\")\n",
        "        g = stats.get(\"gs\")\n",
        "        p = stats.get(\"peak\")\n",
        "        if a is None:\n",
        "            return None, None, None\n",
        "\n",
        "        return float(ee.Number(a).getInfo()), (\n",
        "            float(ee.Number(g).getInfo()) if g else None\n",
        "        ), (\n",
        "            float(ee.Number(p).getInfo()) if p else None\n",
        "        )\n",
        "    except Exception:\n",
        "        return None, None, None\n",
        "\n",
        "def get_water_occurrence(point):\n",
        "    try:\n",
        "        water = ee.Image(\"JRC/GSW1_4/GlobalSurfaceWater\").select(\"occurrence\")\n",
        "        sample = water.sample(\n",
        "            region=point.geometry().buffer(1500),\n",
        "            scale=30,\n",
        "            numPixels=9,\n",
        "        )\n",
        "        if sample.size().getInfo() == 0:\n",
        "            return 0.0, 0.0\n",
        "\n",
        "        mean_occ = sample.aggregate_mean(\"occurrence\")\n",
        "        max_occ  = sample.aggregate_max(\"occurrence\")\n",
        "        return (\n",
        "            float(mean_occ.getInfo()) if mean_occ else 0.0,\n",
        "            float(max_occ.getInfo())  if max_occ  else 0.0,\n",
        "        )\n",
        "    except Exception:\n",
        "        return 0.0, 0.0\n",
        "\n",
        "def get_terrain_data(point):\n",
        "    try:\n",
        "        srtm  = ee.Image(\"USGS/SRTMGL1_003\").select(\"elevation\")\n",
        "        slope = ee.Terrain.slope(srtm)\n",
        "        sample = srtm.addBands(slope).sample(\n",
        "            region=point.geometry().buffer(90),\n",
        "            scale=30,\n",
        "            numPixels=1,\n",
        "        )\n",
        "        if sample.size().getInfo() == 0:\n",
        "            return None, None\n",
        "        feat = sample.first()\n",
        "        return (\n",
        "            float(feat.get(\"elevation\").getInfo()) if feat.get(\"elevation\") else None,\n",
        "            float(feat.get(\"slope\").getInfo())     if feat.get(\"slope\")     else None,\n",
        "        )\n",
        "    except Exception:\n",
        "        return None, None\n",
        "\n",
        "def get_soil_properties(point):\n",
        "    try:\n",
        "        soc  = ee.Image(\n",
        "            \"OpenLandMap/SOL/SOL_ORGANIC-CARBON_USDA-6A1C_M/v02\"\n",
        "        ).select(\"b0\")\n",
        "        clay = ee.Image(\n",
        "            \"OpenLandMap/SOL/SOL_CLAY-WFRACTION_USDA-3A1A1A_M/v02\"\n",
        "        ).select(\"b0\")\n",
        "        sample = soc.addBands(clay).sample(\n",
        "            region=point.geometry().buffer(250),\n",
        "            scale=250,\n",
        "            numPixels=1,\n",
        "        )\n",
        "        if sample.size().getInfo() == 0:\n",
        "            return None, None\n",
        "        feat = sample.first()\n",
        "        soc_gkg  = float(feat.get(\"b0\").getInfo())   if feat.get(\"b0\")   else None\n",
        "        clay_pct = (\n",
        "            float(feat.get(\"b0_1\").getInfo()) / 10.0 if feat.get(\"b0_1\") else None\n",
        "        )\n",
        "        return soc_gkg, clay_pct\n",
        "    except Exception:\n",
        "        return None, None\n",
        "\n",
        "# Sentinel-1 predictors (fixed: global composite, no log10)\n",
        "def build_s1_stack(year):\n",
        "    s1 = (\n",
        "        ee.ImageCollection(\"COPERNICUS/S1_GRD\")\n",
        "        .filterDate(f\"{year}-01-01\", f\"{year}-12-31\")\n",
        "        .filter(ee.Filter.eq(\"instrumentMode\", \"IW\"))\n",
        "        .filter(ee.Filter.eq(\"orbitProperties_pass\", \"DESCENDING\"))\n",
        "        .filter(ee.Filter.eq(\"resolution_meters\", 10))\n",
        "        .filter(ee.Filter.eq(\"productType\", \"GRD\"))\n",
        "        .filter(ee.Filter.listContains(\"transmitterReceiverPolarisation\", \"VV\"))\n",
        "        .filter(ee.Filter.listContains(\"transmitterReceiverPolarisation\", \"VH\"))\n",
        "    )\n",
        "\n",
        "    vv = s1.select(\"VV\").mean().rename(\"s1_vv_mean\")\n",
        "    vh = s1.select(\"VH\").mean().rename(\"s1_vh_mean\")\n",
        "    return vv.addBands(vh)\n",
        "\n",
        "print(\"\\nBuilding Sentinel-1 stack for 2019…\")\n",
        "S1_STACK = build_s1_stack(LABEL_YEAR)\n",
        "print(\"S1 stack ready.\")\n",
        "\n",
        "def get_s1_metrics(point, year):\n",
        "    try:\n",
        "        geom = point.geometry().buffer(60)\n",
        "        stats = S1_STACK.reduceRegion(\n",
        "            reducer=ee.Reducer.mean(),\n",
        "            geometry=geom,\n",
        "            scale=10,\n",
        "            maxPixels=1e7,\n",
        "            bestEffort=True,\n",
        "        )\n",
        "\n",
        "        vv = stats.get(\"s1_vv_mean\")\n",
        "        vh = stats.get(\"s1_vh_mean\")\n",
        "        if vv is None or vh is None:\n",
        "            return None, None\n",
        "\n",
        "        return float(ee.Number(vv).getInfo()), float(ee.Number(vh).getInfo())\n",
        "    except Exception:\n",
        "        return None, None\n",
        "\n",
        "# Sentinel-2 predictors\n",
        "def mask_s2_clouds(img):\n",
        "    qa = img.select(\"QA60\")\n",
        "    cloud_bit  = 1 << 10\n",
        "    cirrus_bit = 1 << 11\n",
        "    cloud  = qa.bitwiseAnd(cloud_bit).neq(0)\n",
        "    cirrus = qa.bitwiseAnd(cirrus_bit).neq(0)\n",
        "    mask   = cloud.Or(cirrus).Not()\n",
        "    return img.updateMask(mask).copyProperties(img, img.propertyNames())\n",
        "\n",
        "def add_s2_indices(img):\n",
        "    scale = 0.0001\n",
        "    b4  = img.select(\"B4\").multiply(scale)\n",
        "    b8  = img.select(\"B8\").multiply(scale)\n",
        "    b8a = img.select(\"B8A\").multiply(scale)\n",
        "\n",
        "    ndvi   = b8.subtract(b4).divide(b8.add(b4).add(1e-6)).rename(\"NDVI\")\n",
        "    re_idx = b8a.subtract(b4).divide(b8a.add(b4).add(1e-6)).rename(\"RE_INDEX\")\n",
        "\n",
        "    return img.addBands([ndvi, re_idx])\n",
        "\n",
        "def get_s2_metrics(point, year):\n",
        "    try:\n",
        "        start_date = f\"{year}-05-01\"\n",
        "        end_date   = f\"{year}-11-30\"\n",
        "\n",
        "        col = (\n",
        "            ee.ImageCollection(S2_COLLECTION)\n",
        "            .filterDate(start_date, end_date)\n",
        "            .filterBounds(point.geometry())\n",
        "            .filter(ee.Filter.lt(\"CLOUDY_PIXEL_PERCENTAGE\", 40))\n",
        "            .map(mask_s2_clouds)\n",
        "            .map(add_s2_indices)\n",
        "            .select([\"NDVI\", \"RE_INDEX\"])\n",
        "        )\n",
        "\n",
        "        if col.size().getInfo() == 0:\n",
        "            return None\n",
        "\n",
        "        composite = (\n",
        "            col.reduce(ee.Reducer.mean())\n",
        "            .addBands(col.reduce(ee.Reducer.max()))\n",
        "            .addBands(col.reduce(ee.Reducer.min()))\n",
        "            .rename(\n",
        "                [\n",
        "                    \"NDVI_mean\",\n",
        "                    \"RE_mean\",\n",
        "                    \"NDVI_max\",\n",
        "                    \"RE_max\",\n",
        "                    \"NDVI_min\",\n",
        "                    \"RE_min\",\n",
        "                ]\n",
        "            )\n",
        "        )\n",
        "\n",
        "        ndvi_amp = composite.select(\"NDVI_max\").subtract(\n",
        "            composite.select(\"NDVI_min\")\n",
        "        ).rename(\"NDVI_amp\")\n",
        "        composite = composite.addBands(ndvi_amp)\n",
        "\n",
        "        geom = point.geometry().buffer(60)\n",
        "        stats = composite.reduceRegion(\n",
        "            reducer=ee.Reducer.mean(),\n",
        "            geometry=geom,\n",
        "            scale=20,\n",
        "            maxPixels=1e7,\n",
        "            bestEffort=True,\n",
        "        )\n",
        "\n",
        "        vals = stats.getInfo()\n",
        "        if vals is None:\n",
        "            return None\n",
        "\n",
        "        out = {}\n",
        "        for k in [\n",
        "            \"NDVI_mean\",\n",
        "            \"NDVI_max\",\n",
        "            \"NDVI_min\",\n",
        "            \"RE_mean\",\n",
        "            \"RE_max\",\n",
        "            \"RE_min\",\n",
        "            \"NDVI_amp\",\n",
        "        ]:\n",
        "            v = vals.get(k)\n",
        "            out[k] = float(v) if v is not None else None\n",
        "\n",
        "        return out\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "# Collect one point\n",
        "def collect_data_for_point(point, region_name, year, point_id, is_rice_val):\n",
        "    try:\n",
        "        coords = point.geometry().coordinates()\n",
        "        row = {\n",
        "            \"point_id\": point_id,\n",
        "            \"region\": region_name,\n",
        "            \"year\": int(year),\n",
        "            \"latitude\": float(coords.get(1).getInfo()),\n",
        "            \"longitude\": float(coords.get(0).getInfo()),\n",
        "            \"is_rice\": int(is_rice_val),\n",
        "        }\n",
        "\n",
        "        mean_evi, max_evi, evi_amp = get_evi_metrics(point, year)\n",
        "        row[\"mean_evi_growing_season\"] = mean_evi\n",
        "        row[\"max_evi_growing_season\"]  = max_evi\n",
        "        row[\"evi_amplitude\"]           = evi_amp\n",
        "\n",
        "        mean_temp, max_temp = get_lst_metrics(point, year)\n",
        "        row[\"mean_temperature_c\"] = mean_temp\n",
        "        row[\"max_temperature_c\"]  = max_temp\n",
        "\n",
        "        annual, gs, peak = get_precipitation_metrics(point, year)\n",
        "        if annual is None:\n",
        "            annual, gs, peak = get_precipitation_metrics_era5(point, year)\n",
        "        row[\"annual_rainfall_mm\"]         = annual\n",
        "        row[\"growing_season_rainfall_mm\"] = gs\n",
        "        row[\"peak_growth_rainfall_mm\"]    = peak\n",
        "\n",
        "        water_mean, water_max = get_water_occurrence(point)\n",
        "        row[\"water_occurrence_mean_pct\"] = water_mean\n",
        "        row[\"water_occurrence_max_pct\"]  = water_max\n",
        "\n",
        "        elevation, slope = get_terrain_data(point)\n",
        "        row[\"elevation_m\"]   = elevation\n",
        "        row[\"slope_degrees\"] = slope\n",
        "\n",
        "        soc, clay = get_soil_properties(point)\n",
        "        row[\"soil_organic_carbon_g_kg\"] = soc\n",
        "        row[\"clay_content_pct\"]         = clay\n",
        "\n",
        "        s1_vv, s1_vh = get_s1_metrics(point, year)\n",
        "        row[\"s1_vv_mean\"] = s1_vv\n",
        "        row[\"s1_vh_mean\"] = s1_vh\n",
        "\n",
        "        s2_vals = get_s2_metrics(point, year)\n",
        "        if s2_vals is not None:\n",
        "            row.update(s2_vals)\n",
        "\n",
        "        return row\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "# Sampling\n",
        "def sample_all_features():\n",
        "    print(\"\\nTHAILAND RICE DATA (2019)\")\n",
        "    print(\"Labels: MSE Asia 2019 | Predictors: ENV + S1 + S2\")\n",
        "    print(f\"Year: {LABEL_YEAR}\")\n",
        "    print(f\"Regions: {list(regions.keys())}\")\n",
        "    if STRATIFY_BY_LABEL:\n",
        "        print(f\"Sampling: STRATIFIED, ~{2 * POINTS_PER_CLASS_PER_REGION}/region\")\n",
        "    else:\n",
        "        print(f\"Sampling: RANDOM {NUM_POINTS_PER_REGION}/region\")\n",
        "\n",
        "    all_rows = []\n",
        "    total_attempted = 0\n",
        "    total_successful = 0\n",
        "    year = LABEL_YEAR\n",
        "\n",
        "    for region_name, region_info in regions.items():\n",
        "        print(f\"\\n== {region_name} ==\")\n",
        "        geom = region_geom(region_info)\n",
        "\n",
        "        if STRATIFY_BY_LABEL:\n",
        "            try:\n",
        "                strat = RICE_IMG.stratifiedSample(\n",
        "                    numPoints=0,\n",
        "                    classBand=\"rice\",\n",
        "                    region=geom,\n",
        "                    scale=20,\n",
        "                    geometries=True,\n",
        "                    classValues=[0, 1],\n",
        "                    classPoints=[\n",
        "                        POINTS_PER_CLASS_PER_REGION,\n",
        "                        POINTS_PER_CLASS_PER_REGION,\n",
        "                    ],\n",
        "                    seed=42,\n",
        "                )\n",
        "            except Exception as e:\n",
        "                print(\"  stratifiedSample failed, falling back:\", e)\n",
        "                strat = None\n",
        "\n",
        "            if strat is None or strat.size().getInfo() == 0:\n",
        "                print(\"  no stratified samples, skipping\")\n",
        "                continue\n",
        "\n",
        "            fc_list = strat.toList(strat.size())\n",
        "            n_pts   = strat.size().getInfo()\n",
        "            print(f\"  candidates: {n_pts}\")\n",
        "\n",
        "            year_success = 0\n",
        "            for i in range(n_pts):\n",
        "                total_attempted += 1\n",
        "                ft = ee.Feature(fc_list.get(i))\n",
        "                is_rice_val = int(ee.Number(ft.get(\"rice\")).getInfo()) if ft.get(\"rice\") is not None else None\n",
        "                if is_rice_val is None:\n",
        "                    continue\n",
        "                pid = f\"{region_name}_{year}_{i}\"\n",
        "                row = collect_data_for_point(ft, region_name, year, pid, is_rice_val)\n",
        "                if row is not None:\n",
        "                    all_rows.append(row)\n",
        "                    year_success += 1\n",
        "                    total_successful += 1\n",
        "                if (i + 1) % 50 == 0:\n",
        "                    print(f\"    processed {i + 1}/{n_pts}\")\n",
        "            print(f\"  done: {year_success}/{n_pts}\")\n",
        "\n",
        "        else:\n",
        "            points = ee.FeatureCollection.randomPoints(\n",
        "                region=geom,\n",
        "                points=NUM_POINTS_PER_REGION,\n",
        "                seed=42,\n",
        "            )\n",
        "            flist  = points.toList(points.size())\n",
        "            year_success = 0\n",
        "            for i in range(NUM_POINTS_PER_REGION):\n",
        "                total_attempted += 1\n",
        "                pt = ee.Feature(flist.get(i))\n",
        "                try:\n",
        "                    v = RICE_IMG.sample(\n",
        "                        region=pt.geometry(),\n",
        "                        scale=20,\n",
        "                        numPixels=1,\n",
        "                        geometries=False,\n",
        "                    ).first()\n",
        "                    if v is None:\n",
        "                        continue\n",
        "                    is_rice_val = int(ee.Number(v.get(\"rice\")).getInfo())\n",
        "                except Exception:\n",
        "                    continue\n",
        "\n",
        "                pid = f\"{region_name}_{year}_{i}\"\n",
        "                row = collect_data_for_point(pt, region_name, year, pid, is_rice_val)\n",
        "                if row is not None:\n",
        "                    all_rows.append(row)\n",
        "                    year_success += 1\n",
        "                    total_successful += 1\n",
        "                if (i + 1) % 50 == 0:\n",
        "                    print(f\"    processed {i + 1}/{NUM_POINTS_PER_REGION}\")\n",
        "            print(f\"  done: {year_success}/{NUM_POINTS_PER_REGION}\")\n",
        "\n",
        "    df = pd.DataFrame(all_rows)\n",
        "    df.to_csv(OUT_CSV, index=False)\n",
        "\n",
        "    print(\"\\nDONE SAMPLING.\")\n",
        "    print(\n",
        "        f\"attempted: {total_attempted} | success: {total_successful} | \"\n",
        "        f\"rate: {(total_successful / total_attempted * 100) if total_attempted else 0:.1f}%\"\n",
        "    )\n",
        "    print(f\"saved: {OUT_CSV}\")\n",
        "\n",
        "    if len(df) > 0:\n",
        "        print(\"\\nSUMMARY (2019)\")\n",
        "        print(f\"rows: {len(df)} | regions: {df['region'].nunique()}\")\n",
        "        print(\n",
        "            f\"rice: {int(df['is_rice'].sum())} ({df['is_rice'].mean() * 100:.1f}%) | \"\n",
        "            f\"non-rice: {len(df) - int(df['is_rice'].sum())}\"\n",
        "        )\n",
        "\n",
        "        print(f\"\\ncols ({len(df.columns)}):\")\n",
        "        print(list(df.columns))\n",
        "\n",
        "        print(\"\\nsample (head):\")\n",
        "        print(df.head())\n",
        "\n",
        "    return df\n",
        "\n",
        "# Random Forest model\n",
        "def train_random_forest(df, n_iter=40, random_state=42):\n",
        "    print(\"\\n=== RANDOM FOREST MODELING (ENV + S1 + S2) ===\")\n",
        "\n",
        "    df_model = df.dropna(subset=[\"is_rice\"]).reset_index(drop=True)\n",
        "    y = df_model[\"is_rice\"].astype(int)\n",
        "\n",
        "    numeric_cols = df_model.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    feature_cols = [c for c in numeric_cols if c != \"is_rice\"]\n",
        "\n",
        "    X = df_model[feature_cols].copy()\n",
        "    X = X.fillna(X.median())\n",
        "\n",
        "    stds = X.std()\n",
        "    keep_cols = [c for c in feature_cols if stds[c] > 1e-6]\n",
        "    X = X[keep_cols]\n",
        "    feature_cols = keep_cols\n",
        "\n",
        "    print(\"Number of features:\", len(feature_cols))\n",
        "    print(\"First 15 features:\", feature_cols[:15])\n",
        "\n",
        "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "        X,\n",
        "        y,\n",
        "        test_size=0.2,\n",
        "        random_state=random_state,\n",
        "        stratify=y,\n",
        "    )\n",
        "\n",
        "    print(\"Train shape:\", X_tr.shape, \"Test shape:\", X_te.shape)\n",
        "\n",
        "    rf_base = RandomForestClassifier(\n",
        "        n_estimators=400,\n",
        "        max_depth=None,\n",
        "        min_samples_leaf=2,\n",
        "        n_jobs=-1,\n",
        "        random_state=random_state,\n",
        "        class_weight=\"balanced_subsample\",\n",
        "    )\n",
        "\n",
        "    param_dist = {\n",
        "        \"max_depth\":         [None, 12, 20, 30],\n",
        "        \"min_samples_split\": [2, 4, 6],\n",
        "        \"min_samples_leaf\":  [1, 2, 4],\n",
        "        \"max_features\":      [\"sqrt\", 0.5, 1.0],\n",
        "        \"bootstrap\":         [True, False],\n",
        "    }\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
        "\n",
        "    random_search = RandomizedSearchCV(\n",
        "        estimator=rf_base,\n",
        "        param_distributions=param_dist,\n",
        "        n_iter=n_iter,\n",
        "        scoring=\"roc_auc\",\n",
        "        n_jobs=-1,\n",
        "        cv=cv,\n",
        "        verbose=2,\n",
        "        random_state=random_state,\n",
        "        refit=True,\n",
        "    )\n",
        "\n",
        "    print(\"\\n=== Hyperparameter search (AUC) ===\")\n",
        "    random_search.fit(X_tr, y_tr)\n",
        "\n",
        "    print(\"\\nBest CV AUC:\", random_search.best_score_)\n",
        "    print(\"Best params:\")\n",
        "    for k, v in random_search.best_params_.items():\n",
        "        print(f\"  {k}: {v}\")\n",
        "\n",
        "    best_rf = random_search.best_estimator_\n",
        "\n",
        "    y_pred  = best_rf.predict(X_te)\n",
        "    y_proba = best_rf.predict_proba(X_te)[:, 1]\n",
        "\n",
        "    print(\"\\n=== Test set performance ===\")\n",
        "    print(classification_report(y_te, y_pred, digits=3))\n",
        "    print(\"Confusion matrix:\")\n",
        "    print(confusion_matrix(y_te, y_pred))\n",
        "\n",
        "    auc_test = roc_auc_score(y_te, y_proba)\n",
        "    print(f\"\\nROC–AUC (test): {auc_test:.3f}\")\n",
        "\n",
        "    importances = pd.Series(best_rf.feature_importances_, index=feature_cols)\n",
        "    importances = importances.sort_values(ascending=False)\n",
        "\n",
        "    print(\"\\nTop 20 most important features:\")\n",
        "    print(importances.head(20).round(4))\n",
        "\n",
        "    return best_rf, feature_cols\n",
        "\n",
        "# Main\n",
        "if __name__ == \"__main__\":\n",
        "    df_all = sample_all_features()\n",
        "\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        files.download(OUT_CSV)\n",
        "        print(f\"\\nDownloaded {OUT_CSV}\")\n",
        "    except Exception:\n",
        "        print(f\"\\nFile saved: {OUT_CSV}\")\n",
        "\n",
        "    if len(df_all) > 0:\n",
        "        best_rf, feature_cols = train_random_forest(df_all)\n"
      ],
      "metadata": {
        "id": "HDIE0fS3VkJc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}